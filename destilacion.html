<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Práctica: Destilación de Conocimiento - Dev Blog</title>
    <style>
        :root {
            --bg-body: #0d1117;
            --text-main: #c9d1d9;
            --text-heading: #ffffff;
            --card-bg: #161b22;
            --border: #30363d;
            --accent: #d2a8ff; /* Purple for AI/ML */
            --font-main: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
            --code-bg: #22272e;
        }

        * { box-sizing: border-box; margin: 0; padding: 0; }

        body {
            background-color: var(--bg-body);
            color: var(--text-main);
            font-family: var(--font-main);
            line-height: 1.6;
            padding: 2rem;
            max-width: 900px;
            margin: 0 auto;
        }

        header {
            margin-bottom: 3rem;
            padding-bottom: 2rem;
            border-bottom: 1px solid var(--border);
        }

        h1 { color: var(--text-heading); font-size: 2.5rem; margin-bottom: 0.5rem; }
        .date { font-size: 0.9rem; color: #8b949e; margin-bottom: 1rem; display: block; }
        
        section { margin-bottom: 3rem; }
        
        h2 { 
            color: var(--accent); 
            font-size: 1.8rem; 
            margin-bottom: 1.5rem; 
            border-bottom: 1px solid rgba(210, 168, 255, 0.2); 
            padding-bottom: 0.5rem;
        }

        h3 { color: var(--text-heading); font-size: 1.3rem; margin: 1.5rem 0 1rem; }

        p { margin-bottom: 1rem; }

        .image-container {
            margin: 2rem 0;
            background-color: var(--card-bg);
            border: 1px solid var(--border);
            border-radius: 6px;
            padding: 1rem;
            text-align: center;
        }

        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        }

        .caption {
            transform: translateY(10px);
            font-size: 0.85rem;
            color: #8b949e;
            margin-top: 0.5rem;
            font-style: italic;
        }

        code {
            font-family: ui-monospace, SFMono-Regular, "SF Mono", Menlo, Consolas, "Liberation Mono", monospace;
            background-color: rgba(110, 118, 129, 0.4);
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-size: 85%;
        }
        
        pre {
            background-color: var(--code-bg);
            padding: 1rem;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1rem;
            border: 1px solid var(--border);
        }

        .alert {
            background-color: rgba(210, 168, 255, 0.1);
            border: 1px solid var(--accent);
            border-radius: 6px;
            padding: 1rem;
            margin: 1.5rem 0;
            color: #e2c0ff;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 1.5rem 0;
        }

        .stat-card {
            background-color: var(--card-bg);
            border: 1px solid var(--border);
            padding: 1.5rem;
            border-radius: 6px;
            text-align: center;
        }

        .stat-value {
            display: block;
            font-size: 2rem;
            color: var(--text-heading);
            font-weight: bold;
        }

        .stat-label {
            color: #8b949e;
            font-size: 0.9rem;
        }

        .back-link {
            display: inline-block;
            margin-top: 2rem;
            color: var(--accent);
            text-decoration: none;
        }

        .back-link:hover { text-decoration: underline; }

    </style>
</head>
<body>

    <header>
        <a href="index.html" class="back-link">← Volver al inicio</a>
        <br><br>
        <h1>Destilación de Conocimiento (Knowledge Distillation)</h1>
        <span class="date">Publicado: 23 de Enero, 2026</span>
        <p>Documentación de la práctica de compresión de modelos de lenguaje (LLMs) utilizando técnicas de destilación profesor-estudiante.</p>
    </header>

    <main>
        
        <section>
            <h2>1. Introducción y Preparación del Entorno</h2>
            <p>El objetivo de esta práctica es aplicar la técnica de <strong>Knowledge Distillation</strong> para transferir el conocimiento de un modelo grande (Teacher) a uno más pequeño (Student), manteniendo la mayor precisión posible mientras se reduce drásticamente el tamaño.</p>
            
            <h3>Creación del Projecto</h3>
            <p>Comenzamos creando la estructura de directorios y aislando nuestras dependencias en un entorno virtual de Python. Esto es crucial para evitar conflictos entre versiones de librerías.</p>
            
            <div class="image-container">
                <img src="asi/Destilación/crear_entorno_destilacion.png" alt="Comandos para crear carpeta y venv">
                <p class="caption">Fig 1. Creación del directorio PracticaDestilacion y preparación del entorno virtual.</p>
            </div>

            <div class="image-container">
                <img src="asi/Destilación/terminal_activacion_venv.png" alt="Terminal activando venv">
                <p class="caption">Fig 2. Activación correcta del entorno virtual en PowerShell.</p>
            </div>

            <h3>Instalación de Dependencias</h3>
            <p>Una vez activo el entorno, instalamos las librerías necesarias: <code>transformers</code> de Hugging Face, <code>datasets</code> para los datos de entrenamiento, y <code>scikit-learn/accelerate</code> para el proceso de cómputo.</p>

            <div class="image-container">
                <img src="asi/Destilación/instalacion_librerias.png" alt="Pip install librerías">
                <p class="caption">Fig 3. Instalación de paquetes necesarios.</p>
            </div>
        </section>

        <section>
            <h2>2. Desarrollo y Debugging</h2>
            <p>Durante la implementación del script de entrenamiento (<code>destilacion_gpu.py</code>), nos encontramos con errores de compatibilidad en la API de Hugging Face.</p>
            
            <div class="alert">
                <strong>Problema detectado:</strong> El parámetro <code>evaluation_strategy</code> en la clase <code>TrainingArguments</code> ha quedado obsoleto o generaba conflicto en la versión actual de la librería.
            </div>

            <div class="image-container">
                <img src="asi/Destilación/error_training_arguments_evaluation_strategy.png" alt="Error Traceback">
                <p class="caption">Fig 4. Traceback mostrando TypeError en TrainingArguments.</p>
            </div>
            
            <p>Fue necesario depurar el código y ajustar los argumentos para alinear la configuración con la versión instalada de <code>transformers</code>.</p>
        </section>

        <section>
            <h2>3. Ejecución del Entrenamiento</h2>
            <p>Procedimos a ejecutar la destilación. Debido a ciertas limitaciones o configuraciones de hardware detectadas en el momento, el script se configuró para forzar el modo CPU o gestionar advertencias sobre la GPU.</p>

            <div class="image-container">
                <img src="asi/Destilación/ejecucion_destilacion_cpu_forzado.png" alt="Ejecución Script">
                <p class="caption">Fig 5. Inicio del proceso de destilación. Se observa la carga del Profesor (DistilBERT) y el Estudiante (TinyBERT).</p>
            </div>
        </section>

        <section>
            <h2>4. Resultados y Métricas</h2>
            <p>Tras finalizar las épocas de entrenamiento, obtuvimos una comparación directa entre el modelo original y el modelo destilado.</p>

            <div class="stats-grid">
                <div class="stat-card">
                    <span class="stat-value">66.96 M</span>
                    <span class="stat-label">Tamaño Profesor</span>
                </div>
                <div class="stat-card">
                    <span class="stat-value">4.39 M</span>
                    <span class="stat-label">Tamaño Estudiante</span>
                </div>
                <div class="stat-card">
                    <span class="stat-value">15.3x</span>
                    <span class="stat-label">Reducción</span>
                </div>
                <div class="stat-card">
                    <span class="stat-value">82.45%</span>
                    <span class="stat-label">Precisión Final</span>
                </div>
            </div>

            <div class="image-container">
                <img src="asi/Destilación/resultados_distilacion_precision_tamano.png" alt="Resultados finales">
                <p class="caption">Fig 6. Log final mostrando la reducción drástica de tamaño y la precisión alcanzada.</p>
            </div>
        </section>

        <section>
            <h2>5. Pruebas de Inferencia</h2>
            <p>Finalmente, validamos cualitativamente el modelo con un script de comparación de sentimientos (<code>comparativa_final.py</code>). El modelo estudiante, pese a ser 15 veces más pequeño, reproduce casi exactamente las predicciones del profesor.</p>

            <div class="image-container">
                <img src="asi/Destilación/comparativa_modelos_sentimientos.png" alt="Tabla comparativa">
                <p class="caption">Fig 7. Tabla comparativa de predicción de sentimientos (Positivo/Negativo) en frases de prueba.</p>
            </div>
        </section>

    </main>

    <footer>
        <p>© 2026 - Documentación Generada para ASI</p>
    </footer>

</body>
</html>
